
---
title: "MQ详解"
date: 2021-10-19
draft: false
tags: ["Java", "MQ"]
slug: "java-mq"
---

## 概念
MQ即messagequeue消息队列，是分布式系统的重要组件，主要解决异步消息，应用解耦，消峰等问题。从而实现高可用，高性能，可伸缩和最终一致性的架构。使用较多的mq有：activeMQ，rabbitMQ，kafka，metaMQ。

- **异步消息处理**：可以将一些非核心流程，如日志，短信，邮件等，通过MQ的方式异步去处理。这样做的好处是缩短主流程的响应时间，提升用户体验；
- **应用解耦合**：商品服务和订单服务之间。用户下单后，订单服务会通知商品服务。不使用MQ的情况是订单服务调用商品服务的接口，这样订单服务和商品服务之间是耦合的；使用MQ，订单服务完成持久化处理，将消息写入MQ消息队列中，返回用户订单下单成功，商品服务来订阅这个下单的消息，采用拉或推的方式获得下单信息，商品服务根据商品下单信息进行商品库存信息修改，这样当下单时商品服务不可用时，也不影响正常下单，这就完成了订单服务和商品服务之间的解耦；
- **流量消峰**：秒杀活动流量过大，导致流量暴增，最终可能导致应用挂掉。一般会在应用前端加入消息队列来控制活动人数，假如消息队列超过最大数量，应该直接抛弃用户请求或者跳转到错误页面。秒杀业务根据消息队列中的请求信息在做后续的业务处理。比如在抢购时，可能一下子过来了10万个请求，但MQ只接受前100个用户的请求，超过100个不接收了。这样就成功限制了用户请求；

## JMS消息模型
JMS即JavaMessageService，Java消息服务应用程序接口，是一个Java平台中关于面向消息中间件的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。

JMS是基于JVM的消息代理规范，ActiveMQ、HornetMQ等是JMS的实现。

Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。我们可以简单的理解：两个应用程序之间需要进行通信，我们使用一个JMS服务，进行中间的转发，通过JMS的使用，我们可以解除两个程序之间的耦合。

### 点对点模式
消息发送者发送消息，消息代理将其放入消息队列中，消息接受者从队列中获取消息，消息读取后被移除消息队列。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到它们被消费或超时。

![MQ详解-001](/iblog/posts/images/essays/MQ详解-001.png)

虽然可能有多个客户端在队列中侦听消息，但只有一个可以读取到消息，之后消息将不存在，其他消费者将无法读取。也就是说消息队列只有唯一一个发送者和*接受者*，但是并不能说只有一个*接收者*。
	
特点：
- 每个消息只有一个消费者，即消息一旦被消费，消息就不在消息队列中；
- 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列；
- 接收者在成功接收消息之后需向队列应答成功；
	
### 发布订阅模式
发布者将消息发送到主题Topic中，多个订阅者订阅这个主题，订阅者不断的去轮询监听消息队列中的消息，那么就会在消息到达的同时接收消息。

![MQ详解-002](/iblog/posts/images/essays/MQ详解-002.png)

特点：
- 每个消息可以有多个消费者，消费完消息之后消息不会清除；
- 发布者和订阅者之间有时间上的依赖性：针对某个主题(Topic)的订阅者，它必须创建一个订阅之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。当然，为了缓和这种严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样即使订阅者没有运行，它也能接收到发布者的消息；

## kafka
kafka是一个分布式的基于发布/订阅模式的消息队列，主要应用于大数据实时处理领域。

### 基础架构
![MQ详解-003](/iblog/posts/images/essays/MQ详解-003.png)

- Producer：消息生产者，向kafka推送消息；
- Consumer：消息消费者，向kafka中broker获取消息的客户端；
- Topic：主题，可以理解为一个队列，生产者和消费者面向的都是一个topic；
- Broker：经纪人，一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic；
- Partition：分区，为了实现扩展性，一个非常大的topic可以分布到多个服务器上，一个主题可以分为多个分区，每个分区是一个有序的队列；
- ConsumerGroup：消费者组，由多个消费者组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者组内的一个消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者；
- Replica：副本，为保证集群中的某个节点发生故障时，该节点上的分区数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower；
- Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。leader是针对topic的，而不是broker的，即不同的kafka服务区中会出现同一个leader；
- Follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个Follower会成为新的leader；

消费者组的作用为了提高消费能力，即提高并发。

解耦合是消息队列作用之一，当消费者宕机后，再次启动的时候会继续消费消息，而不是从头消费消息。因为这个特性所以消费者会保存一些消费的进度信息，被称为offset，保存的位置在kafka0.9之前保存在zookpeer当中，在此之后保存在kafka本地。即最终kafka会将消息保存在本地磁盘中，默认保留168个小时，即7天。

kafka中消息是以topic进行分类的，producer生产消息，consumer消费消息，都是面向topic的。topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。

Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。consumer组中的每个consumer，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。

### 发布订阅工作流程
![MQ详解-004](/iblog/posts/images/essays/MQ详解-004.png)

1. 生产者定期向主题发送消息；
2. kafka代理将所有消息存储在为特定主题配置的分区中。它确保消息在分区之间平均共享。如果生产者发送了两个消息，并且有两个分区，kafka将在第一个分区中存储一个消息，在第二个分区中存储第二个消息；
3. 消费者订阅主题后，kafka将向消费者提供该主题的当前偏移量，并将偏移量保存在Zookeeper集合中；
4. 消费者将定期向kafka请求新消息,一旦kafka从生产者那里收到消息，它将把这些消息转发给消费者，消费者将收到消息并进行处理；
5. 消息处理后，消费者将向kafka代理发送确认；
6. 一旦kafka收到确认，它将偏移量更改为新值并在Zookeeper中对其进行更新。由于在Zookeeper中保留了偏移量，因此即使在服务器出现故障时，使用者也可以正确读取下一条消息；
7. 4、5、6步骤流程将重复进行，直到消费者停止请求为止；

消费者可以选择随时倒退或跳至所需的主题偏移量并阅读所有后续消息。

### 文件存储
参考文章：
- https://www.jianshu.com/p/3e54a5a39683

![MQ详解-005](/iblog/posts/images/essays/MQ详解-005.png)

由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，kafka采取了分片和索引机制，将每个partition分为多个segment。
每个segment对应两个文件：“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为 first-0,first-1,first-2。其中，每个segment中的日志数据文件大小均相等。

> 该日志数据文件的大小可以通过在kafka Broker的config/server.properties配置文件的中的“log.segment.bytes”进行设置，默认为1G大小（1073741824字节），在顺序写入消息时如果超出该设定的阈值，将会创建一组新的日志数据和索引文件。

“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。其中文件的命名是以第一个数据的偏移量来命名的。

**kafka如何通过index文件快速找到log文件中的数据？**

根据指定的偏移量，使用二分法查询定位出该偏移量对应的消息所在的分段索引文件和日志数据文件。然后通过二分查找法，继续查找出小于等于指定偏移量的最大偏移量，同时也得出了对应的position即实际物理位置。

根据该物理位置在分段的日志数据文件中顺序扫描查找偏移量与指定偏移量相等的消息。由于index文件中的每条对应log文件中存储内容大小都相同，所以想要找到指定的消息，只需要用index文件中的该条的大小加上该条的偏移量即可得出log文件中指定消息的位置。

![MQ详解-006](/iblog/posts/images/essays/MQ详解-006.png)


### 生产者分区策略